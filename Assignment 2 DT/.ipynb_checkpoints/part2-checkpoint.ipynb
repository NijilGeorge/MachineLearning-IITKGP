{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "column_file = 'dataset for part 2/words.txt'\n",
    "with open(column_file,\"r\") as f:\n",
    "    columns = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 1061\n",
    "num_words = 3566\n",
    "train_data = {}\n",
    "for i in range(num_docs):\n",
    "    train_data[i] = [0 for j in range(num_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = 'dataset for part 2/traindata.txt'\n",
    "with open(train_data_file,\"r\") as f:\n",
    "    for line in f:\n",
    "        l = line.split()\n",
    "        train_data[int(l[0])-1][int(l[1])-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_file = 'dataset for part 2/trainlabel.txt'\n",
    "with open(train_label_file,\"r\") as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        label = int(line)\n",
    "        train_data[i].append(label)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.DataFrame.from_dict(train_data,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_data_docs = 707\n",
    "test_data = {}\n",
    "for i in range(num_test_data_docs):\n",
    "    test_data[i] = [0 for j in range(num_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = 'dataset for part 2/testdata.txt'\n",
    "with open(test_data_file,\"r\") as f:\n",
    "    for line in f:\n",
    "        l = line.split()\n",
    "        test_data[int(l[0])-1][int(l[1])-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_file = 'dataset for part 2/testlabel.txt'\n",
    "with open(test_label_file,\"r\") as f:\n",
    "    i=0\n",
    "    for line in f:\n",
    "        label = int(line)\n",
    "        test_data[i].append(label)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = pd.DataFrame.from_dict(test_data,orient='index')\n",
    "test_data_df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_parent(df):\n",
    "    entropy_node = 0\n",
    "    values = df['label'].unique()\n",
    "    for value in values:\n",
    "        fraction = df['label'].value_counts()[value]/len(df['label'])\n",
    "        entropy_node += -fraction*np.log2(fraction)\n",
    "    return entropy_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_split(df,attribute):\n",
    "    target_variables = df['label'].unique()\n",
    "    variables = df[attribute].unique()\n",
    "    entropy_attribute = 0\n",
    "    for variable in variables:\n",
    "        entropy_each_feature = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df['label'] == target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy_each_feature += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "        entropy_attribute += -fraction2*entropy_each_feature\n",
    "    return abs(entropy_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(df):\n",
    "    info_gains = []\n",
    "    ent_parent = entropy_parent(df)\n",
    "    for key in df.keys()[:-1]:\n",
    "        info_gains.append(ent_parent - entropy_split(df,key))\n",
    "    return df.keys()[:-1][np.argmax(info_gains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable(df,node,value):\n",
    "    return df[df[node]==value].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df,depth,maxdepth,tree=None):\n",
    "    full_tree = True\n",
    "    node = find_best_split(df)\n",
    "    attValues = np.unique(df[node])\n",
    "    if tree is None:\n",
    "        tree = {}\n",
    "        tree[node] = {}\n",
    "    for value in attValues:\n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable['label'],return_counts=True)\n",
    "        if len(counts)==1:\n",
    "            tree[node][value] = clValue[0]\n",
    "            full_tree = full_tree and True\n",
    "        elif depth == maxdepth:\n",
    "            tree[node][value] = clValue[np.argmax(counts)]\n",
    "            full_tree = False\n",
    "        else:\n",
    "            tree[node][value],temp = build_tree(subtable,depth+1,maxdepth)\n",
    "            full_tree = full_tree and temp\n",
    "    return tree,full_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree,level):\n",
    "    if isinstance(tree,dict):\n",
    "        print('')\n",
    "        attr = list(tree.keys())[0]\n",
    "        for i in tree[attr]:\n",
    "            if level>0:\n",
    "                for j in range(level-1):\n",
    "                    print('\\t',end='')\n",
    "                print('|',end=' ')\n",
    "            print(attr + ' = '+str(i),end=' ')\n",
    "            print_tree(tree[attr][i],level+1)\n",
    "    else:\n",
    "        print(': ' + str(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inst,tree):\n",
    "    for nodes in tree.keys():\n",
    "        value = inst[nodes]\n",
    "        tree = tree[nodes][value]\n",
    "        prediction = ''\n",
    "        if isinstance(tree,dict):\n",
    "            prediction = predict(inst,tree)\n",
    "        else:\n",
    "            prediction = tree\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accuracy(test_x,test_y):\n",
    "    correct = 0\n",
    "    total = len(test_x)\n",
    "    for index,row in test_x.iterrows():\n",
    "        if predict(row,tree)==test_y.iloc[index]:\n",
    "            correct += 1\n",
    "    return 100*(correct)/(total+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_data_df.drop('label',axis=1)\n",
    "test_y = test_data_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data_df.drop('label',axis=1)\n",
    "train_y = train_data_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "False\n",
      "train_acc = 82.09236569274269 test_acc = 81.47100424328147\n",
      "2\n",
      "False\n",
      "train_acc = 83.69462770970782 test_acc = 81.61244695898161\n",
      "3\n",
      "False\n",
      "train_acc = 85.67389255419415 test_acc = 83.5926449787836\n",
      "4\n",
      "False\n",
      "train_acc = 87.8416588124411 test_acc = 81.75388967468176\n",
      "5\n",
      "False\n",
      "train_acc = 90.85768143261075 test_acc = 82.46110325318246\n",
      "6\n",
      "False\n",
      "train_acc = 92.17719132893497 test_acc = 82.31966053748232\n",
      "7\n",
      "False\n",
      "train_acc = 93.49670122525919 test_acc = 80.90523338048091\n",
      "8\n",
      "False\n",
      "train_acc = 94.81621112158341 test_acc = 82.88543140028288\n",
      "9\n",
      "False\n",
      "train_acc = 95.85296889726673 test_acc = 81.61244695898161\n",
      "10\n",
      "False\n",
      "train_acc = 96.60697455230914 test_acc = 82.17821782178218\n",
      "11\n",
      "False\n",
      "train_acc = 97.54948162111216 test_acc = 81.75388967468176\n",
      "12\n",
      "False\n",
      "train_acc = 98.11498586239397 test_acc = 81.75388967468176\n",
      "13\n",
      "False\n",
      "train_acc = 98.49198868991517 test_acc = 81.18811881188118\n",
      "14\n",
      "False\n",
      "train_acc = 98.96324222431669 test_acc = 81.75388967468176\n",
      "15\n",
      "False\n",
      "train_acc = 99.34024505183788 test_acc = 81.61244695898161\n",
      "16\n",
      "False\n",
      "train_acc = 99.43449575871819 test_acc = 81.61244695898161\n",
      "17\n",
      "False\n",
      "train_acc = 99.62299717247879 test_acc = 81.47100424328147\n",
      "18\n",
      "False\n",
      "train_acc = 99.71724787935909 test_acc = 80.76379066478076\n",
      "19\n",
      "True\n",
      "train_acc = 100.0 test_acc = 80.62234794908062\n"
     ]
    }
   ],
   "source": [
    "training_acc = []\n",
    "testing_acc = []\n",
    "full_tree = False\n",
    "size = 1\n",
    "while not full_tree:\n",
    "    print(size)\n",
    "    tree,full_tree = build_tree(train_data_df,0,size)\n",
    "    print(full_tree)\n",
    "    train_acc = predict_accuracy(train_x,train_y)\n",
    "    test_acc = predict_accuracy(test_x,test_y)\n",
    "    training_acc.append(train_acc)\n",
    "    testing_acc.append(test_acc)\n",
    "    print('train_acc = '+str(train_acc)+' test_acc = '+str(test_acc))\n",
    "    size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = list(range(1,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
